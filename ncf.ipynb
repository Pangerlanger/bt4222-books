{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "# !pip install torch torchvision torchaudio pandas scikit-learn\n",
    "\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pj/nr405prs69j7fp08s_fm2qc40000gn/T/ipykernel_99031/2830472867.py:2: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_children_books_final_encoded = pd.read_csv('df_children_books_final_encoded.csv')\n"
     ]
    }
   ],
   "source": [
    "df_children_books_final = pd.read_csv('df_children_books_final.csv')\n",
    "df_children_books_final_encoded = pd.read_csv('df_children_books_final_encoded.csv')\n",
    "df_interactions_final_merged = pd.read_csv('df_interactions_final_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text_incomplete</th>\n",
       "      <th>date_added</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>review_age</th>\n",
       "      <th>processed_review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>23310161</td>\n",
       "      <td>f4b4b050f4be00e9283c92a814af2670</td>\n",
       "      <td>4</td>\n",
       "      <td>Fun sequel to the original.</td>\n",
       "      <td>2015-11-17 19:37:35+00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3248</td>\n",
       "      <td>fun sequel original</td>\n",
       "      <td>0.680800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>18296097</td>\n",
       "      <td>bc9cff98f54be3b2b8c5b34598a7546c</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-21 15:16:57+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.574139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>817720</td>\n",
       "      <td>75fd46041466ceb406b7fd69b089b9c5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-05-21 04:29:23+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.574139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id   book_id  \\\n",
       "0  8842281e1d1347389f2ab93d60773d4d  23310161   \n",
       "1  8842281e1d1347389f2ab93d60773d4d  18296097   \n",
       "2  8842281e1d1347389f2ab93d60773d4d    817720   \n",
       "\n",
       "                          review_id  rating       review_text_incomplete  \\\n",
       "0  f4b4b050f4be00e9283c92a814af2670       4  Fun sequel to the original.   \n",
       "1  bc9cff98f54be3b2b8c5b34598a7546c       5                          NaN   \n",
       "2  75fd46041466ceb406b7fd69b089b9c5       5                          NaN   \n",
       "\n",
       "                  date_added  n_votes  review_age     processed_review  \\\n",
       "0  2015-11-17 19:37:35+00:00      7.0        3248  fun sequel original   \n",
       "1  2015-09-21 15:16:57+00:00      NaN        3305                  NaN   \n",
       "2  2015-05-21 04:29:23+00:00      NaN        3429                  NaN   \n",
       "\n",
       "   sentiment  \n",
       "0   0.680800  \n",
       "1   0.574139  \n",
       "2   0.574139  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interactions_final_merged.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "userid_encoder = LabelEncoder()\n",
    "bookid_encoder = LabelEncoder()\n",
    "\n",
    "df_interactions_final_merged['user_id'] = userid_encoder.fit_transform(df_interactions_final_merged['user_id'])\n",
    "df_interactions_final_merged['book_id'] = bookid_encoder.fit_transform(df_interactions_final_merged['book_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_id, group in df_interactions_final_merged.groupby('user_id'):\n",
    "    split_idx = int(len(group) * 0.8) \n",
    "    train_data.append(group.iloc[:split_idx])\n",
    "    test_data.append(group.iloc[split_idx:])\n",
    "\n",
    "train_data = pd.concat(train_data, ignore_index=True)\n",
    "test_data = pd.concat(test_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (5054073, 10)\n",
      "Testing data shape: (1572916, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"Testing data shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User 0:\n",
      "  Train samples: 4\n",
      "  Test samples: 1\n",
      "  Train ratio: 0.80\n",
      "\n",
      "User 1:\n",
      "  Train samples: 27\n",
      "  Test samples: 7\n",
      "  Train ratio: 0.79\n",
      "\n",
      "User 2:\n",
      "  Train samples: 1\n",
      "  Test samples: 1\n",
      "  Train ratio: 0.50\n",
      "\n",
      "User 3:\n",
      "  Train samples: 1\n",
      "  Test samples: 1\n",
      "  Train ratio: 0.50\n",
      "\n",
      "User 4:\n",
      "  Train samples: 4\n",
      "  Test samples: 1\n",
      "  Train ratio: 0.80\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for user_id in range(5): \n",
    "  user_train = train_data[train_data['user_id'] == user_id]\n",
    "  user_test = test_data[test_data['user_id'] == user_id]\n",
    "  print(f\"\\nUser {user_id}:\")\n",
    "  print(f\"  Train samples: {len(user_train)}\")\n",
    "  print(f\"  Test samples: {len(user_test)}\")\n",
    "  print(f\"  Train ratio: {len(user_train) / (len(user_train) + len(user_test)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering out users and books in the test set that do not appear in the training set.\n",
    "\n",
    "This is done so that we can see if our model has learnt user's previous item interactions and can recommend relevant books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique users and items from the training data\n",
    "train_users = set(train_data['user_id'].unique())\n",
    "train_items = set(train_data['book_id'].unique())\n",
    "\n",
    "# Filter the test set\n",
    "filtered_test_data = test_data[\n",
    "    test_data['user_id'].isin(train_users) & test_data['book_id'].isin(train_items)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440373\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text_incomplete</th>\n",
       "      <th>date_added</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>review_age</th>\n",
       "      <th>processed_review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>480</td>\n",
       "      <td>b5c7c0ca89779a65111ae924633ecf38</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-12-07 20:11:06+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>53356</td>\n",
       "      <td>5c0f20ebfbd0cfdddac5fab9f9523346</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-04-06 01:26:16+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32555</td>\n",
       "      <td>8b3b8f80e33fa6ebaded76a15b8d71d3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-04-06 01:26:10+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>487</td>\n",
       "      <td>69b2e638da62a121dc91c8295453dcda</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-04-06 01:24:19+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11363</td>\n",
       "      <td>afae540b29bbf5b0cccae5174d6041d2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-04-06 01:24:11+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.208501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id                         review_id  rating  \\\n",
       "0        0      480  b5c7c0ca89779a65111ae924633ecf38       1   \n",
       "1        1    53356  5c0f20ebfbd0cfdddac5fab9f9523346       4   \n",
       "2        1    32555  8b3b8f80e33fa6ebaded76a15b8d71d3       4   \n",
       "3        1      487  69b2e638da62a121dc91c8295453dcda       4   \n",
       "4        1    11363  afae540b29bbf5b0cccae5174d6041d2       2   \n",
       "\n",
       "  review_text_incomplete                 date_added  n_votes  review_age  \\\n",
       "0                    NaN  2014-12-07 20:11:06+00:00      NaN        3593   \n",
       "1                    NaN  2013-04-06 01:26:16+00:00      NaN        4204   \n",
       "2                    NaN  2013-04-06 01:26:10+00:00      NaN        4204   \n",
       "3                    NaN  2013-04-06 01:24:19+00:00      NaN        4204   \n",
       "4                    NaN  2013-04-06 01:24:11+00:00      NaN        4204   \n",
       "\n",
       "  processed_review  sentiment  \n",
       "0              NaN  -0.018937  \n",
       "1              NaN   0.527973  \n",
       "2              NaN   0.527973  \n",
       "3              NaN   0.527973  \n",
       "4              NaN   0.208501  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(filtered_test_data))\n",
    "filtered_test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BooksDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        return {\n",
    "            'user_id': torch.tensor(row['user_id'], dtype=torch.long),\n",
    "            'book_id': torch.tensor(row['book_id'], dtype=torch.long),\n",
    "            'sentiment': torch.tensor(row['sentiment'], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 512\n",
    "\n",
    "train_dataset = BooksDataset(train_data)\n",
    "test_dataset = BooksDataset(test_data)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuMF model with GMF and MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the NCF model with GMF and MLP for Books Data\n",
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_books, embedding_dim):\n",
    "        super(NCF, self).__init__()\n",
    "        # GMF Components\n",
    "        self.user_embeddings_gmf = nn.Embedding(num_users, embedding_dim)\n",
    "        self.book_embeddings_gmf = nn.Embedding(num_books, embedding_dim)\n",
    "\n",
    "        # MLP Components\n",
    "        self.user_embeddings_mlp = nn.Embedding(num_users, embedding_dim)\n",
    "        self.book_embeddings_mlp = nn.Embedding(num_books, embedding_dim)\n",
    "\n",
    "        self.fc1_mlp = nn.Linear(2 * embedding_dim, 128)\n",
    "        self.fc2_mlp = nn.Linear(128, 64)\n",
    "\n",
    "        # Final layers\n",
    "        self.fc1_combined = nn.Linear(embedding_dim + 64, 128)\n",
    "        self.fc2_combined = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, user_id, book_id):\n",
    "        # GMF\n",
    "        user_emb_gmf = self.user_embeddings_gmf(user_id)\n",
    "        book_emb_gmf = self.book_embeddings_gmf(book_id)\n",
    "        gmf_output = user_emb_gmf * book_emb_gmf\n",
    "\n",
    "        # MLP\n",
    "        user_emb_mlp = self.user_embeddings_mlp(user_id)\n",
    "        book_emb_mlp = self.book_embeddings_mlp(book_id)\n",
    "        mlp_input = torch.cat([user_emb_mlp, book_emb_mlp], dim=-1)\n",
    "        mlp_output = torch.relu(self.fc1_mlp(mlp_input))\n",
    "        mlp_output = torch.relu(self.fc2_mlp(mlp_output))\n",
    "\n",
    "        # Combine GMF and MLP outputs\n",
    "        combined_input = torch.cat([gmf_output, mlp_output], dim=-1)\n",
    "        combined_output = torch.relu(self.fc1_combined(combined_input))\n",
    "        combined_output = torch.relu(self.fc2_combined(combined_output)) * 4 + 1  # To match rating scale\n",
    "\n",
    "        return combined_output.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and train the model\n",
    "embedding_dim = 32\n",
    "num_users = len(userid_encoder.classes_) \n",
    "num_books = len(bookid_encoder.classes_)  \n",
    "\n",
    "model = NCF(num_users, num_books, embedding_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in train_loader:\n",
    "        user_id = batch['user_id']\n",
    "        book_id = batch['book_id']\n",
    "        sentiment = batch['sentiment']\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(user_id, book_id)\n",
    "        loss = criterion(outputs, sentiment)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_data)}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    for batch in test_loader:\n",
    "        user_id = batch['user_id']\n",
    "        book_id = batch['book_id']\n",
    "        sentiment = batch['sentiment']\n",
    "\n",
    "        outputs = model(user_id, book_id)\n",
    "        loss = criterion(outputs, sentiment)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    test_loss = total_loss / len(test_data)\n",
    "    print(f'Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Predictions\n",
    "\n",
    "Use trained GMF+MLP model to generate predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(model, data_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            user_id = batch['user_id']\n",
    "            book_id = batch['book_id']\n",
    "            outputs = model(user_id, book_id)\n",
    "            predictions.extend(zip(user_id.numpy(), book_id.numpy(), outputs.numpy()))\n",
    "    return predictions\n",
    "\n",
    "# Generate predictions\n",
    "test_predictions = generate_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_bt4222Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
