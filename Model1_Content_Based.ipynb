{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries & methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, \n",
    "    mean_squared_error, mean_absolute_error, ndcg_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = pd.read_csv('df_books_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tried using cosine similarity on those new features (does not work, not enough memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concatenate 'title' and 'description' columns into a new column 'title_description'\n",
    "# df_books['title_description'] = df_books['title'] + \" \" + df_books['description']\n",
    "\n",
    "# from gensim.models import Word2Vec\n",
    "\n",
    "# book_descriptions = df_books['title_description']\n",
    "\n",
    "# # Tokenize book descriptions\n",
    "# tokenized_descriptions = [description.split() for description in book_descriptions]\n",
    "\n",
    "# # Train Word2Vec model\n",
    "# model = Word2Vec(tokenized_descriptions, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# # To get a single vector for an entire description, average the word vectors\n",
    "# def get_vector(text):\n",
    "#     words = text.split()\n",
    "#     word_vectors = np.array([model.wv[word] for word in words if word in model.wv])\n",
    "#     return np.mean(word_vectors, axis=0) if word_vectors.size else np.zeros(model.vector_size)\n",
    "\n",
    "# # Vectorize descriptions\n",
    "# descriptions_vectors = np.array([get_vector(description) for description in book_descriptions])\n",
    "\n",
    "# # Create a DataFrame with 100 new columns for the word vectors\n",
    "# vector_columns = pd.DataFrame(descriptions_vectors, columns=[f'vector_{i+1}' for i in range(descriptions_vectors.shape[1])])\n",
    "# # Concatenate the vector columns with the original df_books DataFrame\n",
    "# df_books_with_vectors = pd.concat([df_books, vector_columns], axis=1)\n",
    "\n",
    "# df_books_with_vectors = df_books_with_vectors.drop(columns=['top_popular_shelves'])\n",
    "\n",
    "# df_books_with_vectors.head(3)\n",
    "\n",
    "# # convert the string representation of lists into actual lists and then extract the first element as an integer\n",
    "# df_books_with_vectors['author_id_int'] = df_books_with_vectors['author_ids'].apply(lambda x: int(ast.literal_eval(x)[0]) if x else None)\n",
    "# # type int64\n",
    "# df_books_with_vectors['author_id_int'] = df_books_with_vectors['author_id_int'].astype('Int64')\n",
    "\n",
    "# df_books_final = df_books_with_vectors.drop(columns=['author_ids', 'title', 'description', 'title_description'])\n",
    "\n",
    "# bool_columns = df_books_final.select_dtypes(include=['bool']).columns\n",
    "# df_books_final[bool_columns] = df_books_final[bool_columns].astype(int)\n",
    "# print(df_books_final.head(3))\n",
    "\n",
    "\n",
    "# # Select only the numeric columns (int, float)\n",
    "# df_books_numeric = df_books_final.select_dtypes(include=[int, float])\n",
    "\n",
    "# # Convert the DataFrame to a sparse matrix\n",
    "# from scipy.sparse import csr_matrix\n",
    "# df_books_sparse = csr_matrix(df_books_numeric.values)\n",
    "\n",
    "\n",
    "# books_cos_sim = cosine_similarity(df_books_final, dense_output = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine test and training\n",
    "for each user id inside, recommend some books,\n",
    "compare that recommendation with what he actually read "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Feature Engineering for Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59828, 149225)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculation of TFIDF scores for 'description'\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_scores =  tfidf.fit_transform(df_books['description'])\n",
    "tfidf_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cosine similarity matrix directly for the TF-IDF matrix\n",
    "tfidf_cos_sim = cosine_similarity(tfidf_scores, dense_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Recommendations on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interactions = pd.read_csv('train_interactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by user_id, review_age (ascending for lowest first), and rating (descending for highest first)\n",
    "train_interactions_sorted = train_interactions.sort_values(\n",
    "    by=['user_id', 'review_age', 'rating'], ascending=[True, True, False]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collate every user's read book history to account for previous user-book interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by user_id and select top 3 books based on the sorted order\n",
    "user_reading_history = (\n",
    "    train_interactions_sorted.groupby('user_id')\n",
    "    .head(3)  # Take top 3 rows per user\n",
    "    .groupby('user_id')['book_id']\n",
    "    .apply(list)  # Aggregate book_ids into a list\n",
    "    .reset_index()\n",
    "    .rename(columns={'book_id': 'books_id_read'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>books_id_read</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[157993, 359079, 41684]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[34524, 236093, 17131769]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[24213, 5, 194755]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[134371, 10444, 42359]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[8144, 5, 6680753]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id              books_id_read\n",
       "0        0    [157993, 359079, 41684]\n",
       "1        1  [34524, 236093, 17131769]\n",
       "2        2         [24213, 5, 194755]\n",
       "3        3     [134371, 10444, 42359]\n",
       "4        4         [8144, 5, 6680753]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_reading_history.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all books read previously, we want to take a single book with the highest similarity score among read books to act as a book that is most representative of a user's preference. Using that reference book, we can identify other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute cumulative similarity scores and find the reference book\n",
    "def get_reference_book(books_id_read, books_df, similarity_matrix):\n",
    "    cumulative_scores = {}\n",
    "    \n",
    "    # For each book in the user's reading history\n",
    "    for book_id in books_id_read:\n",
    "        try:\n",
    "            # Get the index of the book in df_books to match the similarity matrix\n",
    "            book_index = books_df.index[books_df['book_id'] == book_id][0]\n",
    "            \n",
    "            # Compute similarity scores with all other books in books_id_read\n",
    "            similarity_scores = [\n",
    "                similarity_matrix[book_index, books_df.index[books_df['book_id'] == other_book_id][0]]\n",
    "                for other_book_id in books_id_read if other_book_id != book_id\n",
    "            ]\n",
    "            \n",
    "            # Calculate cumulative similarity score for the current book\n",
    "            cumulative_scores[book_id] = sum(similarity_scores)\n",
    "          \n",
    "        except IndexError:\n",
    "            # Skip books that may not be in the similarity matrix\n",
    "            continue\n",
    "    # Find the book with the highest cumulative similarity score\n",
    "    reference_book = max(cumulative_scores, key=cumulative_scores.get) if cumulative_scores else None\n",
    "    return reference_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>books_id_read</th>\n",
       "      <th>reference_book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[157993, 359079, 41684]</td>\n",
       "      <td>41684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[34524, 236093, 17131769]</td>\n",
       "      <td>34524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[24213, 5, 194755]</td>\n",
       "      <td>24213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[134371, 10444, 42359]</td>\n",
       "      <td>42359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[8144, 5, 6680753]</td>\n",
       "      <td>8144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id              books_id_read  reference_book\n",
       "0        0    [157993, 359079, 41684]           41684\n",
       "1        1  [34524, 236093, 17131769]           34524\n",
       "2        2         [24213, 5, 194755]           24213\n",
       "3        3     [134371, 10444, 42359]           42359\n",
       "4        4         [8144, 5, 6680753]            8144"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to find the reference book for each user\n",
    "user_reading_history['reference_book'] = user_reading_history['books_id_read'].apply(\n",
    "    lambda books_id_read: get_reference_book(books_id_read, df_books, tfidf_cos_sim)\n",
    ")\n",
    "\n",
    "user_reading_history.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get top N most similar books for a reference book\n",
    "def get_top_n_similar_books(reference_book_id, books_df, similarity_matrix, top_n=10):\n",
    "    # Get the index of the reference book in books_df\n",
    "    try:\n",
    "        ref_book_index = books_df.index[books_df['book_id'] == reference_book_id][0]\n",
    "    except IndexError:\n",
    "        # Return an empty list if the reference_book_id is not found in books_df\n",
    "        return []\n",
    "    \n",
    "    # Get similarity scores for all books with respect to the reference book\n",
    "    similarity_scores = similarity_matrix[ref_book_index].toarray().flatten()\n",
    "    \n",
    "    # Create a list of (book_id, similarity_score) tuples, excluding the reference book itself\n",
    "    similar_books = [\n",
    "        (books_df.iloc[i]['book_id'], similarity_scores[i])\n",
    "        for i in range(len(similarity_scores)) if books_df.iloc[i]['book_id'] != reference_book_id\n",
    "    ]\n",
    "    \n",
    "    # Sort by similarity score in descending order and take top N\n",
    "    top_similar_books = sorted(similar_books, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    \n",
    "    # Extract book IDs of the top similar books\n",
    "    top_book_ids = [book_id for book_id, _ in top_similar_books]\n",
    "    return top_book_ids\n",
    "\n",
    "# # get book title recommendations\n",
    "# def get_top_n_similar_books(reference_book_id, books_df, similarity_matrix, top_n=5):\n",
    "#     # Get the index of the reference book in books_df\n",
    "#     try:\n",
    "#         ref_book_index = books_df.index[books_df['book_id'] == reference_book_id][0]\n",
    "#     except IndexError:\n",
    "#         # Return an empty list if the reference_book_id is not found in books_df\n",
    "#         return []\n",
    "\n",
    "#     # Get similarity scores for all books with respect to the reference book\n",
    "#     similarity_scores = similarity_matrix[ref_book_index].toarray().flatten()\n",
    "\n",
    "#     # Create a list of (book_id, similarity_score) tuples, excluding the reference book itself\n",
    "#     similar_books = [\n",
    "#         (books_df.iloc[i]['book_id'], books_df.iloc[i]['title'], similarity_scores[i])\n",
    "#         for i in range(len(similarity_scores))\n",
    "#         if books_df.iloc[i]['book_id'] != reference_book_id\n",
    "#     ]\n",
    "\n",
    "#     # Sort by similarity score in descending order and take top N\n",
    "#     top_similar_books = sorted(similar_books, key=lambda x: x[2], reverse=True)[:top_n]\n",
    "\n",
    "#     # Extract titles of the top similar books\n",
    "#     top_book_titles = [title for _, title, _ in top_similar_books]\n",
    "#     return top_book_titles\n",
    "\n",
    "\n",
    "## to get similarity score along with book id and title\n",
    "\n",
    "# def get_top_n_similar_books(reference_book_id, books_df, similarity_matrix, top_n=5):\n",
    "#     # Get the index of the reference book in books_df\n",
    "#     try:\n",
    "#         ref_book_index = books_df.index[books_df['book_id'] == reference_book_id][0]\n",
    "#     except IndexError:\n",
    "#         # Return an empty list if the reference_book_id is not found in books_df\n",
    "#         return []\n",
    "\n",
    "#     # Get similarity scores for all books with respect to the reference book\n",
    "#     similarity_scores = similarity_matrix[ref_book_index].toarray().flatten()\n",
    "\n",
    "#     # Create a list of (book_id, title, similarity_score) tuples, excluding the reference book itself\n",
    "#     similar_books = [\n",
    "#         (books_df.iloc[i]['book_id'], books_df.iloc[i]['title'], similarity_scores[i])\n",
    "#         for i in range(len(similarity_scores))\n",
    "#         if books_df.iloc[i]['book_id'] != reference_book_id\n",
    "#     ]\n",
    "\n",
    "#     # Sort by similarity score in descending order and take top N\n",
    "#     top_similar_books = sorted(similar_books, key=lambda x: x[2], reverse=True)[:top_n]\n",
    "\n",
    "#     # Return top similar books with ID, title, and similarity score\n",
    "#     return top_similar_books\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for User 7 (Reference Book 32929):\n",
      "[1099989, 232381, 94559, 1099991, 32932]\n"
     ]
    }
   ],
   "source": [
    "# # test case: Recommend books for sample user 7\n",
    "\n",
    "user_id = 7\n",
    "user_7_data = user_reading_history[user_reading_history['user_id'] == user_id]\n",
    "\n",
    "# Ensure user 7 has a reference book\n",
    "if not user_7_data.empty:\n",
    "    reference_book_id = user_7_data['reference_book'].values[0]\n",
    "    \n",
    "    # Get the top 5 recommendations for user 7's reference book\n",
    "    recommendations_user_7 = get_top_n_similar_books(reference_book_id, df_books, tfidf_cos_sim, top_n=5)\n",
    "    \n",
    "    print(f\"Top 5 recommendations for User {user_id} (Reference Book {reference_book_id}):\")\n",
    "    print(recommendations_user_7)\n",
    "else:\n",
    "    print(f\"User {user_id} not found in user_reading_history.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our implementation, we are recommending 5 books for users 1 - 1000 and evaluating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 500 rows of user_reading_history\n",
    "top_1000_user_reading_history = user_reading_history.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xy/8rz0nq295qgbl2mbhxxfq05m0000gn/T/ipykernel_8094/1335992504.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_1000_user_reading_history['recommendations'] = top_1000_user_reading_history['reference_book'].apply(\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to each user in user_reading_history to get recommendations\n",
    "top_1000_user_reading_history['recommendations'] = top_1000_user_reading_history['reference_book'].apply(\n",
    "    lambda ref_book: get_top_n_similar_books(ref_book, df_books, tfidf_cos_sim, top_n=5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>books_id_read</th>\n",
       "      <th>reference_book</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[157993, 359079, 41684]</td>\n",
       "      <td>41684</td>\n",
       "      <td>[1150470, 1009934, 3426335, 9046908, 29363115]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[34524, 236093, 17131769]</td>\n",
       "      <td>34524</td>\n",
       "      <td>[16190512, 1343087, 26109114, 1847543, 842002]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[24213, 5, 194755]</td>\n",
       "      <td>24213</td>\n",
       "      <td>[12197986, 38686, 1068933, 1956182, 70453]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id              books_id_read  reference_book  \\\n",
       "0        0    [157993, 359079, 41684]           41684   \n",
       "1        1  [34524, 236093, 17131769]           34524   \n",
       "2        2         [24213, 5, 194755]           24213   \n",
       "\n",
       "                                  recommendations  \n",
       "0  [1150470, 1009934, 3426335, 9046908, 29363115]  \n",
       "1  [16190512, 1343087, 26109114, 1847543, 842002]  \n",
       "2      [12197986, 38686, 1068933, 1956182, 70453]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top_3_user_reading_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommending for users 1 - 1000 in Test Set (due to time constraints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date_added</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>review_age</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>343002</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-01-25 00:26:06+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4641</td>\n",
       "      <td>0.574139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1852</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-01-21 18:36:06+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4644</td>\n",
       "      <td>0.527973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1248128</td>\n",
       "      <td>4</td>\n",
       "      <td>2009-05-04 15:32:21+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5636</td>\n",
       "      <td>0.527973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating                 date_added  n_votes  review_age  \\\n",
       "0        0   343002       5  2012-01-25 00:26:06+00:00      NaN        4641   \n",
       "1        0     1852       4  2012-01-21 18:36:06+00:00      NaN        4644   \n",
       "2        1  1248128       4  2009-05-04 15:32:21+00:00      NaN        5636   \n",
       "\n",
       "   sentiment  \n",
       "0   0.574139  \n",
       "1   0.527973  \n",
       "2   0.527973  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_interactions = pd.read_csv('test_interactions.csv')\n",
    "test_interactions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by user_id and select top 3 books based on the sorted order\n",
    "user_test = (\n",
    "    test_interactions.groupby('user_id')\n",
    "    .head(3)  # Take top 3 rows per user\n",
    "    .groupby('user_id')['book_id']\n",
    "    .apply(list)  # Aggregate book_ids into a list\n",
    "    .reset_index()\n",
    "    .rename(columns={'book_id': 'books_id_read'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_test_top_1000 = user_test.head(1000)\n",
    "# user_test_top_1000.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hit Rate: Check if the 5 recommendations for each user are actually read in the test set\n",
    "#### Validity of recommendation: Calculate the average similarity score between the recommendations and read books "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the average similarity score among all actual read books and recommended books\n",
    "def calculate_avg_similarity(user_id, actual_books_read, recommendations, books_df, similarity_matrix):\n",
    "    all_similarity_scores = []\n",
    "    \n",
    "    for actual_book_id in actual_books_read:\n",
    "        try:\n",
    "            # Get the index of the actual book in books_df\n",
    "            actual_book_index = books_df.index[books_df['book_id'] == actual_book_id][0]\n",
    "        except IndexError:\n",
    "            # Skip if the actual book is not in books_df\n",
    "            all_similarity_scores.append(None)\n",
    "            continue\n",
    "        \n",
    "        # Calculate similarity between each recommended book and the actual books read\n",
    "        for recommended_book_id in recommendations:\n",
    "            try:\n",
    "                recommended_book_index = books_df.index[books_df['book_id'] == recommended_book_id][0]\n",
    "                similarity_score = similarity_matrix[actual_book_index, recommended_book_index]\n",
    "                all_similarity_scores.append(similarity_score)\n",
    "            except IndexError:\n",
    "                # Skip if the recommended book is not in books_df\n",
    "                continue\n",
    "    \n",
    "    return np.average(all_similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>books_id_read</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>max_similarity_scores</th>\n",
       "      <th>avg_similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[343002, 1852]</td>\n",
       "      <td>[1150470, 1009934, 3426335, 9046908, 29363115]</td>\n",
       "      <td>[0.04252608615023137, 0.047140118602314714]</td>\n",
       "      <td>0.020710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[1248128, 30119]</td>\n",
       "      <td>[16190512, 1343087, 26109114, 1847543, 842002]</td>\n",
       "      <td>[0.01034420398048235, 0.013824423369103476]</td>\n",
       "      <td>0.005388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[74595, 2711313]</td>\n",
       "      <td>[12197986, 38686, 1068933, 1956182, 70453]</td>\n",
       "      <td>[0.022517120971567876, 0.005899712413665775]</td>\n",
       "      <td>0.007727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[30119, 157993]</td>\n",
       "      <td>[2830856, 3200616, 822392, 42331, 370495]</td>\n",
       "      <td>[0.020098251059419647, 0.022648563485515742]</td>\n",
       "      <td>0.006475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[13023, 157993]</td>\n",
       "      <td>[19290672, 823598, 18051057, 18051056, 3017558]</td>\n",
       "      <td>[0.03238304484039952, 0.016681591975954726]</td>\n",
       "      <td>0.017383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>[24178, 78411]</td>\n",
       "      <td>[30139, 30137, 838059, 838073, 30132]</td>\n",
       "      <td>[0.04874861866795203, 0.016531585364157587]</td>\n",
       "      <td>0.024292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>[267972, 275000]</td>\n",
       "      <td>[1252480, 847692, 1252452, 1252496, 446848]</td>\n",
       "      <td>[0.024311902137199932, 0.021052906385195583]</td>\n",
       "      <td>0.012646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>[25618438, 23754884]</td>\n",
       "      <td>[17190400, 16054810, 18594577, 1329131, 6871059]</td>\n",
       "      <td>[0.023090530125603085, 0.007369528119377128]</td>\n",
       "      <td>0.007771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>[140225, 5]</td>\n",
       "      <td>[1222825, 7063752, 334013, 1121411, 2956698]</td>\n",
       "      <td>[0.05729717480779167, 0.014608194798619899]</td>\n",
       "      <td>0.035362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>[157993, 3008]</td>\n",
       "      <td>[13005376, 5972044, 8907049, 13548617, 11827175]</td>\n",
       "      <td>[0.005924661279288851, 0.0]</td>\n",
       "      <td>0.000592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id         books_id_read  \\\n",
       "0          0        [343002, 1852]   \n",
       "1          1      [1248128, 30119]   \n",
       "2          2      [74595, 2711313]   \n",
       "3          3       [30119, 157993]   \n",
       "4          4       [13023, 157993]   \n",
       "..       ...                   ...   \n",
       "995      995        [24178, 78411]   \n",
       "996      996      [267972, 275000]   \n",
       "997      997  [25618438, 23754884]   \n",
       "998      998           [140225, 5]   \n",
       "999      999        [157993, 3008]   \n",
       "\n",
       "                                      recommendations  \\\n",
       "0      [1150470, 1009934, 3426335, 9046908, 29363115]   \n",
       "1      [16190512, 1343087, 26109114, 1847543, 842002]   \n",
       "2          [12197986, 38686, 1068933, 1956182, 70453]   \n",
       "3           [2830856, 3200616, 822392, 42331, 370495]   \n",
       "4     [19290672, 823598, 18051057, 18051056, 3017558]   \n",
       "..                                                ...   \n",
       "995             [30139, 30137, 838059, 838073, 30132]   \n",
       "996       [1252480, 847692, 1252452, 1252496, 446848]   \n",
       "997  [17190400, 16054810, 18594577, 1329131, 6871059]   \n",
       "998      [1222825, 7063752, 334013, 1121411, 2956698]   \n",
       "999  [13005376, 5972044, 8907049, 13548617, 11827175]   \n",
       "\n",
       "                            max_similarity_scores  avg_similarity_score  \n",
       "0     [0.04252608615023137, 0.047140118602314714]              0.020710  \n",
       "1     [0.01034420398048235, 0.013824423369103476]              0.005388  \n",
       "2    [0.022517120971567876, 0.005899712413665775]              0.007727  \n",
       "3    [0.020098251059419647, 0.022648563485515742]              0.006475  \n",
       "4     [0.03238304484039952, 0.016681591975954726]              0.017383  \n",
       "..                                            ...                   ...  \n",
       "995   [0.04874861866795203, 0.016531585364157587]              0.024292  \n",
       "996  [0.024311902137199932, 0.021052906385195583]              0.012646  \n",
       "997  [0.023090530125603085, 0.007369528119377128]              0.007771  \n",
       "998   [0.05729717480779167, 0.014608194798619899]              0.035362  \n",
       "999                   [0.005924661279288851, 0.0]              0.000592  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the top_3_user_reading_history and user_test_top_3 dataframes to align recommendations with actual reads\n",
    "merged_df = pd.merge(\n",
    "    top_1000_user_reading_history[['user_id', 'recommendations']],\n",
    "    user_test_top_1000[['user_id', 'books_id_read']],\n",
    "    on='user_id'\n",
    ")\n",
    "\n",
    "merged_df['avg_similarity_score'] = merged_df.apply(\n",
    "    lambda row: calculate_avg_similarity(\n",
    "        row['user_id'],\n",
    "        row['books_id_read'],\n",
    "        row['recommendations'],\n",
    "        df_books,\n",
    "        tfidf_cos_sim\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Show the results\n",
    "merged_df[['user_id', 'books_id_read', 'recommendations', 'max_similarity_scores','avg_similarity_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in recommendation & similarity scores from CSV (merged_df exceeds local memory limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv(\"1000user_recommendations(content).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting the number of matches in recommendations and actually read books for every user recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding 'num_exact_match' columns to merged_df\n",
    "# num_exact_match is the number of recommendations that are actually read by the users\n",
    "merged_df['num_exact_match'] = merged_df.apply(\n",
    "    lambda row: sum(1 for book_id in row['recommendations'] if book_id in row['books_id_read']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>books_id_read</th>\n",
       "      <th>max_similarity_scores</th>\n",
       "      <th>avg_similarity_score</th>\n",
       "      <th>num_exact_match</th>\n",
       "      <th>avg_max_similarity_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[1150470, 1009934, 3426335, 9046908, 29363115]</td>\n",
       "      <td>[343002, 1852]</td>\n",
       "      <td>[0.04252608615023137, 0.047140118602314714]</td>\n",
       "      <td>0.020710</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[16190512, 1343087, 26109114, 1847543, 842002]</td>\n",
       "      <td>[1248128, 30119]</td>\n",
       "      <td>[0.01034420398048235, 0.013824423369103476]</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[12197986, 38686, 1068933, 1956182, 70453]</td>\n",
       "      <td>[74595, 2711313]</td>\n",
       "      <td>[0.022517120971567876, 0.005899712413665775]</td>\n",
       "      <td>0.007727</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                 recommendations     books_id_read  \\\n",
       "0        0  [1150470, 1009934, 3426335, 9046908, 29363115]    [343002, 1852]   \n",
       "1        1  [16190512, 1343087, 26109114, 1847543, 842002]  [1248128, 30119]   \n",
       "2        2      [12197986, 38686, 1068933, 1956182, 70453]  [74595, 2711313]   \n",
       "\n",
       "                          max_similarity_scores  avg_similarity_score  \\\n",
       "0   [0.04252608615023137, 0.047140118602314714]              0.020710   \n",
       "1   [0.01034420398048235, 0.013824423369103476]              0.005388   \n",
       "2  [0.022517120971567876, 0.005899712413665775]              0.007727   \n",
       "\n",
       "   num_exact_match  avg_max_similarity_scores  \n",
       "0                0                   0.044833  \n",
       "1                0                   0.012084  \n",
       "2                0                   0.014208  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarities between recommendations and actually read books are generally quite low with the median average score at 0.0126. This indicates that the recommendations provided to each user are not that similar to previously read books. However, this may also be due to an absence of relevant books in the training data due to memory constraints in our local machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean        0.027905\n",
       "std         0.054445\n",
       "min         0.000000\n",
       "25%         0.007529\n",
       "50%         0.012594\n",
       "75%         0.020113\n",
       "max         0.395172\n",
       "Name: avg_similarity_score, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['avg_similarity_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04727481418403913"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_threshold = merged_df['avg_similarity_score'].quantile(0.9)\n",
    "similarity_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the recommendation system in terms of exact match is 1.10%\n"
     ]
    }
   ],
   "source": [
    "#hit rate = number of relevant recommendations/ total recommendations\n",
    "total_users = 1000\n",
    "total_hits = merged_df['num_exact_match'].sum()\n",
    "# print(total_hits)\n",
    "accuracy_of_exact_hits = total_hits/total_users * 100 # checking for accuracy of recommendation. hits/total_books\n",
    "print(f\"The accuracy of the recommendation system in terms of exact match is {accuracy_of_exact_hits:.2f}%\")\n",
    "\n",
    "# similarity_threshold = 0.20 # to determine if recommended book is good in terms of similarity\n",
    "# count = (merged_df['avg_similarity_score'] >= similarity_threshold).sum()\n",
    "# accuracy_similarity = count/total_users * 100\n",
    "# # print(count)\n",
    "# print(f\"The accuracy of the recommendation system in terms of similarity is {accuracy_similarity:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@K: 0.7484415108177485\n",
      "Recall@K: 0.9795546170090228\n",
      "F1 Score: 0.8485428013137654\n",
      "Confusion Matrix:\n",
      " [[    0  3430]\n",
      " [  213 10205]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to hold true/false positives and negatives\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "# Calculate TP, FP, FN for each user\n",
    "for _, row in merged_df.iterrows():\n",
    "    recommendations = set(row['recommendations'])\n",
    "    books_read = set(row['books_id_read'])\n",
    "\n",
    "    # True Positives (recommended and read)\n",
    "    tp = recommendations.intersection(books_read)\n",
    "    \n",
    "    # False Positives (recommended but not read)\n",
    "    fp = recommendations - books_read\n",
    "    \n",
    "    # False Negatives (read but not recommended)\n",
    "    fn = books_read - recommendations\n",
    "    \n",
    "    # Append results to the lists\n",
    "    # True positives are marked as 1 in both y_true and y_pred\n",
    "    all_y_true.extend([1] * len(tp))\n",
    "    all_y_pred.extend([1] * len(tp))\n",
    "    \n",
    "    # False positives are marked as 0 in y_true and 1 in y_pred\n",
    "    all_y_true.extend([0] * len(fp))\n",
    "    all_y_pred.extend([1] * len(fp))\n",
    "    \n",
    "    # False negatives are marked as 1 in y_true and 0 in y_pred\n",
    "    all_y_true.extend([1] * len(fn))\n",
    "    all_y_pred.extend([0] * len(fn))\n",
    "\n",
    "\n",
    "#Precision@K\n",
    "precision = precision_score(all_y_true,  all_y_pred)\n",
    "print(f\"Precision@K: {precision}\")\n",
    "\n",
    "#Recall@K\n",
    "recall = recall_score( all_y_true,  all_y_pred)\n",
    "print(f\"Recall@K: {recall}\")\n",
    "\n",
    "#F1 Score\n",
    "f1 = f1_score(all_y_true, all_y_pred)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "#Confusion Matrix\n",
    "conf_matrix = confusion_matrix(all_y_true, all_y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
