{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-Based Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries & methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = pd.read_csv('df_books_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interactions = pd.read_csv('train_interactions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Matrix Using Book Metadata\n",
    "\n",
    "We tried to create a similarity matrix using the book metadata (vectorized title & description using Word2Vec, genre, format, and other feature engineered columns). We experimented calculating cosine similarity using both the dense and the sparse matrix representations, but ran into memory issues for both methods as the matrix was too large. Thus, we proceeded with finding similarities between books using TF-IDF of the book descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concatenate 'title' and 'description' columns into a new column 'title_description'\n",
    "# df_books['title_description'] = df_books['title'] + \" \" + df_books['description']\n",
    "\n",
    "# from gensim.models import Word2Vec\n",
    "\n",
    "# book_descriptions = df_books['title_description']\n",
    "\n",
    "# # Tokenize book descriptions\n",
    "# tokenized_descriptions = [description.split() for description in book_descriptions]\n",
    "\n",
    "# # Train Word2Vec model\n",
    "# model = Word2Vec(tokenized_descriptions, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# # To get a single vector for an entire description, average the word vectors\n",
    "# def get_vector(text):\n",
    "#     words = text.split()\n",
    "#     word_vectors = np.array([model.wv[word] for word in words if word in model.wv])\n",
    "#     return np.mean(word_vectors, axis=0) if word_vectors.size else np.zeros(model.vector_size)\n",
    "\n",
    "# # Vectorize descriptions\n",
    "# descriptions_vectors = np.array([get_vector(description) for description in book_descriptions])\n",
    "\n",
    "# # Create a DataFrame with 100 new columns for the word vectors\n",
    "# vector_columns = pd.DataFrame(descriptions_vectors, columns=[f'vector_{i+1}' for i in range(descriptions_vectors.shape[1])])\n",
    "# # Concatenate the vector columns with the original df_books DataFrame\n",
    "# df_books_with_vectors = pd.concat([df_books, vector_columns], axis=1)\n",
    "\n",
    "# df_books_with_vectors = df_books_with_vectors.drop(columns=['top_popular_shelves'])\n",
    "\n",
    "# df_books_with_vectors.head(3)\n",
    "\n",
    "# # convert the string representation of lists into actual lists and then extract the first element as an integer\n",
    "# df_books_with_vectors['author_id_int'] = df_books_with_vectors['author_ids'].apply(lambda x: int(ast.literal_eval(x)[0]) if x else None)\n",
    "# # type int64\n",
    "# df_books_with_vectors['author_id_int'] = df_books_with_vectors['author_id_int'].astype('Int64')\n",
    "\n",
    "# df_books_final = df_books_with_vectors.drop(columns=['author_ids', 'title', 'description', 'title_description'])\n",
    "\n",
    "# bool_columns = df_books_final.select_dtypes(include=['bool']).columns\n",
    "# df_books_final[bool_columns] = df_books_final[bool_columns].astype(int)\n",
    "# print(df_books_final.head(3))\n",
    "\n",
    "\n",
    "# # Select only the numeric columns (int, float)\n",
    "# df_books_numeric = df_books_final.select_dtypes(include=[int, float])\n",
    "\n",
    "# # Convert the DataFrame to a sparse matrix\n",
    "# from scipy.sparse import csr_matrix\n",
    "# df_books_sparse = csr_matrix(df_books_numeric.values)\n",
    "\n",
    "\n",
    "# books_cos_sim = cosine_similarity(df_books_final, dense_output = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization of Book Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59828, 149225)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculation of TFIDF scores for 'description'\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_scores =  tfidf.fit_transform(df_books['description'])\n",
    "tfidf_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cosine similarity matrix directly for the TF-IDF matrix\n",
    "tfidf_cos_sim = cosine_similarity(tfidf_scores, dense_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Recommendations Using Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by user_id, review_age (ascending for lowest first), and rating (descending for highest first)\n",
    "train_interactions_sorted = train_interactions.sort_values(\n",
    "    by=['user_id', 'review_age', 'rating'], ascending=[True, True, False]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining User's History of Books Read\n",
    "\n",
    "We initially wanted to account for all books in the reading history, but generating recommendations for each book in the history took too much time. Thus, to account for a user's reading history when generating recommendations, we took the 3 most recent and most highly rated books from the users reading history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by user_id and select top 3 books based on the sorted order\n",
    "user_reading_history = (\n",
    "    train_interactions_sorted.groupby('user_id')\n",
    "    .head(3)  # Take top 3 rows per user\n",
    "    .groupby('user_id')['book_id']\n",
    "    .apply(list)  # Aggregate book_ids into a list\n",
    "    .reset_index()\n",
    "    .rename(columns={'book_id': 'books_id_read'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>books_id_read</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[157993, 359079, 41684]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[34524, 236093, 17131769]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[24213, 5, 194755]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[134371, 10444, 42359]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[8144, 5, 6680753]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id              books_id_read\n",
       "0        0    [157993, 359079, 41684]\n",
       "1        1  [34524, 236093, 17131769]\n",
       "2        2         [24213, 5, 194755]\n",
       "3        3     [134371, 10444, 42359]\n",
       "4        4         [8144, 5, 6680753]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_reading_history.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then filtered out the book with the highest similarity with the other books in the top 3 to generate book recommendations for each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute cumulative similarity scores and find the reference book\n",
    "def get_reference_book(books_id_read, books_df, similarity_matrix):\n",
    "    cumulative_scores = {}\n",
    "    \n",
    "    # For each book in the user's reading history\n",
    "    for book_id in books_id_read:\n",
    "        try:\n",
    "            # Get the index of the book in df_books to match the similarity matrix\n",
    "            book_index = books_df.index[books_df['book_id'] == book_id][0]\n",
    "            \n",
    "            # Compute similarity scores with all other books in books_id_read\n",
    "            similarity_scores = [\n",
    "                similarity_matrix[book_index, books_df.index[books_df['book_id'] == other_book_id][0]]\n",
    "                for other_book_id in books_id_read if other_book_id != book_id\n",
    "            ]\n",
    "            \n",
    "            # Calculate cumulative similarity score for the current book\n",
    "            cumulative_scores[book_id] = sum(similarity_scores)\n",
    "          \n",
    "        except IndexError:\n",
    "            # Skip books that may not be in the similarity matrix\n",
    "            continue\n",
    "    # Find the book with the highest cumulative similarity score\n",
    "    reference_book = max(cumulative_scores, key=cumulative_scores.get) if cumulative_scores else None\n",
    "    return reference_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>books_id_read</th>\n",
       "      <th>reference_book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[157993, 359079, 41684]</td>\n",
       "      <td>41684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[34524, 236093, 17131769]</td>\n",
       "      <td>34524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[24213, 5, 194755]</td>\n",
       "      <td>24213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[134371, 10444, 42359]</td>\n",
       "      <td>42359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[8144, 5, 6680753]</td>\n",
       "      <td>8144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id              books_id_read  reference_book\n",
       "0        0    [157993, 359079, 41684]           41684\n",
       "1        1  [34524, 236093, 17131769]           34524\n",
       "2        2         [24213, 5, 194755]           24213\n",
       "3        3     [134371, 10444, 42359]           42359\n",
       "4        4         [8144, 5, 6680753]            8144"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to find the reference book for each user\n",
    "user_reading_history['reference_book'] = user_reading_history['books_id_read'].apply(\n",
    "    lambda books_id_read: get_reference_book(books_id_read, df_books, tfidf_cos_sim)\n",
    ")\n",
    "\n",
    "user_reading_history.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get top N most similar books for a reference book\n",
    "def get_top_n_similar_books(reference_book_id, books_df, similarity_matrix, top_n=5):\n",
    "    # Get the index of the reference book in books_df\n",
    "    try:\n",
    "        ref_book_index = books_df.index[books_df['book_id'] == reference_book_id][0]\n",
    "    except IndexError:\n",
    "        # Return an empty list if the reference_book_id is not found in books_df\n",
    "        return []\n",
    "    \n",
    "    # Get similarity scores for all books with respect to the reference book\n",
    "    similarity_scores = similarity_matrix[ref_book_index].toarray().flatten()\n",
    "    \n",
    "    # Create a list of (book_id, similarity_score) tuples, excluding the reference book itself\n",
    "    similar_books = [\n",
    "        (books_df.iloc[i]['book_id'], similarity_scores[i])\n",
    "        for i in range(len(similarity_scores)) if books_df.iloc[i]['book_id'] != reference_book_id\n",
    "    ]\n",
    "    \n",
    "    # Sort by similarity score in descending order and take top N\n",
    "    top_similar_books = sorted(similar_books, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    \n",
    "    # Extract book IDs of the top similar books\n",
    "    top_book_ids = [book_id for book_id, _ in top_similar_books]\n",
    "    return top_book_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for User 7 (Reference Book 32929):\n",
      "[1099989, 232381, 94559, 1099991, 32932]\n"
     ]
    }
   ],
   "source": [
    "# test case: Recommend books for sample user 7\n",
    "\n",
    "user_id = 7\n",
    "user_7_data = user_reading_history[user_reading_history['user_id'] == user_id]\n",
    "\n",
    "# Ensure user 7 has a reference book\n",
    "if not user_7_data.empty:\n",
    "    reference_book_id = user_7_data['reference_book'].values[0]\n",
    "    \n",
    "    # Get the top 5 recommendations for user 7's reference book\n",
    "    recommendations_user_7 = get_top_n_similar_books(reference_book_id, df_books, tfidf_cos_sim, top_n=5)\n",
    "    \n",
    "    print(f\"Top 5 recommendations for User {user_id} (Reference Book {reference_book_id}):\")\n",
    "    print(recommendations_user_7)\n",
    "else:\n",
    "    print(f\"User {user_id} not found in user_reading_history.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend 5 books for each of the first 1000 users to evaluate the recommendations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 1000 rows of user_reading_history\n",
    "top_1000_user_reading_history = user_reading_history.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xy/8rz0nq295qgbl2mbhxxfq05m0000gn/T/ipykernel_8094/1335992504.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_1000_user_reading_history['recommendations'] = top_1000_user_reading_history['reference_book'].apply(\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to each user in user_reading_history to get recommendations\n",
    "top_1000_user_reading_history['recommendations'] = top_1000_user_reading_history['reference_book'].apply(\n",
    "    lambda ref_book: get_top_n_similar_books(ref_book, df_books, tfidf_cos_sim, top_n=5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date_added</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>review_age</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>343002</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-01-25 00:26:06+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4641</td>\n",
       "      <td>0.574139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1852</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-01-21 18:36:06+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4644</td>\n",
       "      <td>0.527973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1248128</td>\n",
       "      <td>4</td>\n",
       "      <td>2009-05-04 15:32:21+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5636</td>\n",
       "      <td>0.527973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating                 date_added  n_votes  review_age  \\\n",
       "0        0   343002       5  2012-01-25 00:26:06+00:00      NaN        4641   \n",
       "1        0     1852       4  2012-01-21 18:36:06+00:00      NaN        4644   \n",
       "2        1  1248128       4  2009-05-04 15:32:21+00:00      NaN        5636   \n",
       "\n",
       "   sentiment  \n",
       "0   0.574139  \n",
       "1   0.527973  \n",
       "2   0.527973  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_interactions = pd.read_csv('test_interactions.csv')\n",
    "test_interactions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by user_id and select top 3 books based on the sorted order\n",
    "user_test = (\n",
    "    test_interactions.groupby('user_id')\n",
    "    .head(3)  # Take top 3 rows per user\n",
    "    .groupby('user_id')['book_id']\n",
    "    .apply(list)  # Aggregate book_ids into a list\n",
    "    .reset_index()\n",
    "    .rename(columns={'book_id': 'books_id_read'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_test_top_1000 = user_test.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the average similarity score among all actual read books and recommended books\n",
    "def calculate_avg_similarity(user_id, actual_books_read, recommendations, books_df, similarity_matrix):\n",
    "    all_similarity_scores = []\n",
    "    \n",
    "    for actual_book_id in actual_books_read:\n",
    "        try:\n",
    "            # Get the index of the actual book in books_df\n",
    "            actual_book_index = books_df.index[books_df['book_id'] == actual_book_id][0]\n",
    "        except IndexError:\n",
    "            # Skip if the actual book is not in books_df\n",
    "            all_similarity_scores.append(None)\n",
    "            continue\n",
    "        \n",
    "        # Calculate similarity between each recommended book and the actual books read\n",
    "        for recommended_book_id in recommendations:\n",
    "            try:\n",
    "                recommended_book_index = books_df.index[books_df['book_id'] == recommended_book_id][0]\n",
    "                similarity_score = similarity_matrix[actual_book_index, recommended_book_index]\n",
    "                all_similarity_scores.append(similarity_score)\n",
    "            except IndexError:\n",
    "                # Skip if the recommended book is not in books_df\n",
    "                continue\n",
    "    \n",
    "    return np.average(all_similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>books_id_read</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>max_similarity_scores</th>\n",
       "      <th>avg_similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[343002, 1852]</td>\n",
       "      <td>[1150470, 1009934, 3426335, 9046908, 29363115]</td>\n",
       "      <td>[0.04252608615023137, 0.047140118602314714]</td>\n",
       "      <td>0.020710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[1248128, 30119]</td>\n",
       "      <td>[16190512, 1343087, 26109114, 1847543, 842002]</td>\n",
       "      <td>[0.01034420398048235, 0.013824423369103476]</td>\n",
       "      <td>0.005388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[74595, 2711313]</td>\n",
       "      <td>[12197986, 38686, 1068933, 1956182, 70453]</td>\n",
       "      <td>[0.022517120971567876, 0.005899712413665775]</td>\n",
       "      <td>0.007727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[30119, 157993]</td>\n",
       "      <td>[2830856, 3200616, 822392, 42331, 370495]</td>\n",
       "      <td>[0.020098251059419647, 0.022648563485515742]</td>\n",
       "      <td>0.006475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[13023, 157993]</td>\n",
       "      <td>[19290672, 823598, 18051057, 18051056, 3017558]</td>\n",
       "      <td>[0.03238304484039952, 0.016681591975954726]</td>\n",
       "      <td>0.017383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>[24178, 78411]</td>\n",
       "      <td>[30139, 30137, 838059, 838073, 30132]</td>\n",
       "      <td>[0.04874861866795203, 0.016531585364157587]</td>\n",
       "      <td>0.024292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>[267972, 275000]</td>\n",
       "      <td>[1252480, 847692, 1252452, 1252496, 446848]</td>\n",
       "      <td>[0.024311902137199932, 0.021052906385195583]</td>\n",
       "      <td>0.012646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>[25618438, 23754884]</td>\n",
       "      <td>[17190400, 16054810, 18594577, 1329131, 6871059]</td>\n",
       "      <td>[0.023090530125603085, 0.007369528119377128]</td>\n",
       "      <td>0.007771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>[140225, 5]</td>\n",
       "      <td>[1222825, 7063752, 334013, 1121411, 2956698]</td>\n",
       "      <td>[0.05729717480779167, 0.014608194798619899]</td>\n",
       "      <td>0.035362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>[157993, 3008]</td>\n",
       "      <td>[13005376, 5972044, 8907049, 13548617, 11827175]</td>\n",
       "      <td>[0.005924661279288851, 0.0]</td>\n",
       "      <td>0.000592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id         books_id_read  \\\n",
       "0          0        [343002, 1852]   \n",
       "1          1      [1248128, 30119]   \n",
       "2          2      [74595, 2711313]   \n",
       "3          3       [30119, 157993]   \n",
       "4          4       [13023, 157993]   \n",
       "..       ...                   ...   \n",
       "995      995        [24178, 78411]   \n",
       "996      996      [267972, 275000]   \n",
       "997      997  [25618438, 23754884]   \n",
       "998      998           [140225, 5]   \n",
       "999      999        [157993, 3008]   \n",
       "\n",
       "                                      recommendations  \\\n",
       "0      [1150470, 1009934, 3426335, 9046908, 29363115]   \n",
       "1      [16190512, 1343087, 26109114, 1847543, 842002]   \n",
       "2          [12197986, 38686, 1068933, 1956182, 70453]   \n",
       "3           [2830856, 3200616, 822392, 42331, 370495]   \n",
       "4     [19290672, 823598, 18051057, 18051056, 3017558]   \n",
       "..                                                ...   \n",
       "995             [30139, 30137, 838059, 838073, 30132]   \n",
       "996       [1252480, 847692, 1252452, 1252496, 446848]   \n",
       "997  [17190400, 16054810, 18594577, 1329131, 6871059]   \n",
       "998      [1222825, 7063752, 334013, 1121411, 2956698]   \n",
       "999  [13005376, 5972044, 8907049, 13548617, 11827175]   \n",
       "\n",
       "                            max_similarity_scores  avg_similarity_score  \n",
       "0     [0.04252608615023137, 0.047140118602314714]              0.020710  \n",
       "1     [0.01034420398048235, 0.013824423369103476]              0.005388  \n",
       "2    [0.022517120971567876, 0.005899712413665775]              0.007727  \n",
       "3    [0.020098251059419647, 0.022648563485515742]              0.006475  \n",
       "4     [0.03238304484039952, 0.016681591975954726]              0.017383  \n",
       "..                                            ...                   ...  \n",
       "995   [0.04874861866795203, 0.016531585364157587]              0.024292  \n",
       "996  [0.024311902137199932, 0.021052906385195583]              0.012646  \n",
       "997  [0.023090530125603085, 0.007369528119377128]              0.007771  \n",
       "998   [0.05729717480779167, 0.014608194798619899]              0.035362  \n",
       "999                   [0.005924661279288851, 0.0]              0.000592  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the top_3_user_reading_history and user_test_top_3 dataframes to align recommendations with actual reads\n",
    "merged_df = pd.merge(\n",
    "    top_1000_user_reading_history[['user_id', 'recommendations']],\n",
    "    user_test_top_1000[['user_id', 'books_id_read']],\n",
    "    on='user_id'\n",
    ")\n",
    "\n",
    "merged_df['avg_similarity_score'] = merged_df.apply(\n",
    "    lambda row: calculate_avg_similarity(\n",
    "        row['user_id'],\n",
    "        row['books_id_read'],\n",
    "        row['recommendations'],\n",
    "        df_books,\n",
    "        tfidf_cos_sim\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Show the results\n",
    "merged_df[['user_id', 'books_id_read', 'recommendations', 'max_similarity_scores','avg_similarity_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in recommendation & similarity scores from CSV (merged_df exceeds local memory limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv(\"1000user_recommendations(content).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting the number of matches in recommendations and actually read books for every user recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>books_id_read</th>\n",
       "      <th>max_similarity_scores</th>\n",
       "      <th>avg_similarity_score</th>\n",
       "      <th>num_exact_match</th>\n",
       "      <th>avg_max_similarity_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[1150470, 1009934, 3426335, 9046908, 29363115]</td>\n",
       "      <td>[343002, 1852]</td>\n",
       "      <td>[0.04252608615023137, 0.047140118602314714]</td>\n",
       "      <td>0.020710</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[16190512, 1343087, 26109114, 1847543, 842002]</td>\n",
       "      <td>[1248128, 30119]</td>\n",
       "      <td>[0.01034420398048235, 0.013824423369103476]</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[12197986, 38686, 1068933, 1956182, 70453]</td>\n",
       "      <td>[74595, 2711313]</td>\n",
       "      <td>[0.022517120971567876, 0.005899712413665775]</td>\n",
       "      <td>0.007727</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                 recommendations     books_id_read  \\\n",
       "0        0  [1150470, 1009934, 3426335, 9046908, 29363115]    [343002, 1852]   \n",
       "1        1  [16190512, 1343087, 26109114, 1847543, 842002]  [1248128, 30119]   \n",
       "2        2      [12197986, 38686, 1068933, 1956182, 70453]  [74595, 2711313]   \n",
       "\n",
       "                          max_similarity_scores  avg_similarity_score  \\\n",
       "0   [0.04252608615023137, 0.047140118602314714]              0.020710   \n",
       "1   [0.01034420398048235, 0.013824423369103476]              0.005388   \n",
       "2  [0.022517120971567876, 0.005899712413665775]              0.007727   \n",
       "\n",
       "   num_exact_match  avg_max_similarity_scores  \n",
       "0                0                   0.044833  \n",
       "1                0                   0.012084  \n",
       "2                0                   0.014208  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean        0.027905\n",
       "std         0.054445\n",
       "min         0.000000\n",
       "25%         0.007529\n",
       "50%         0.012594\n",
       "75%         0.020113\n",
       "max         0.395172\n",
       "Name: avg_similarity_score, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['avg_similarity_score'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initially considered using a threshold similarity score to evaluate the accuracy of the model. However, setting the threshold too low would give us a high accuracy even when recommendations are likely to be bad, but setting the threshold too high would not be favourable either. Thus, as there was no benchmark or research showing what threshold we should use, we ultimately decided to evaluate our model based off the average similarity score of the predicted books with the books in the test set.\n",
    "\n",
    "As seen in the table above, similarities between recommendations and actually read books are generally quite low with the median average score at 0.0126. This indicates that the recommendations provided to each user are not that similar to previously read books. However, this may also be due to an absence of relevant books in the training data due to memory constraints in our local machines. Furthermore, we only generated recommendations for the first 1000 users in the dataset and thus, our results might not be representative of the population in our entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "Hit Rate: Check if the 5 recommendations for each user are actually read in the test set\n",
    "\n",
    "Validity of recommendation: Calculate the average similarity score between the recommendations and read books "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to hold true/false positives and negatives\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "total_hits = 0\n",
    "\n",
    "# Calculate TP, FP, FN for each user\n",
    "for _, row in merged_df.iterrows():\n",
    "    recommendations = list(map(int, row['recommendations'].strip(\"[]\").split(\", \")))\n",
    "    books_read = list(map(int, row['books_id_read'].strip(\"[]\").split(\", \")))\n",
    "    \n",
    "    tp = len(set(recommendations) & set(books_read))  # True Positives: in both lists\n",
    "    fp = len(set(recommendations) - set(books_read))  # False Positives: recommended but not read\n",
    "    fn = len(set(books_read) - set(recommendations))  # False Negatives: read but not recommended\n",
    "\n",
    "    total_hits += tp\n",
    "    \n",
    "    # Append results to the lists\n",
    "    # True positives are marked as 1 in both y_true and y_pred\n",
    "    all_y_true.extend([1] * tp)\n",
    "    all_y_pred.extend([1] * tp)\n",
    "    \n",
    "    # False positives are marked as 0 in y_true and 1 in y_pred\n",
    "    all_y_true.extend([0] * fp)\n",
    "    all_y_pred.extend([1] * fp)\n",
    "    \n",
    "    # False negatives are marked as 1 in y_true and 0 in y_pred\n",
    "    all_y_true.extend([1] * fn)\n",
    "    all_y_pred.extend([0] * fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the recommendation system in terms of exact match is 1.10%\n"
     ]
    }
   ],
   "source": [
    "# hit rate = number of relevant recommendations/ total recommendations\n",
    "total_users = 1000\n",
    "accuracy_of_exact_hits = total_hits/total_users * 100 # checking for accuracy of recommendation. hits/total_books\n",
    "print(f\"The accuracy of the recommendation system in terms of exact match is {accuracy_of_exact_hits:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall, F1-Score, Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@K: 0.0022\n",
      "Recall@K: 0.0055\n",
      "F1 Score: 0.003142857142857143\n",
      "Confusion Matrix:\n",
      " [[   0 4989]\n",
      " [1989   11]]\n"
     ]
    }
   ],
   "source": [
    "#Precision@K\n",
    "precision = precision_score(all_y_true,  all_y_pred)\n",
    "print(f\"Precision@K: {precision}\")\n",
    "\n",
    "#Recall@K\n",
    "recall = recall_score( all_y_true,  all_y_pred)\n",
    "print(f\"Recall@K: {recall}\")\n",
    "\n",
    "#F1 Score\n",
    "f1 = f1_score(all_y_true, all_y_pred)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "#Confusion Matrix\n",
    "conf_matrix = confusion_matrix(all_y_true, all_y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
